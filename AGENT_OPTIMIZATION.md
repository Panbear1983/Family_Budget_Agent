# Improvements & Roadmap ğŸš§

Complete guide to features in progress, known issues, optimizations, and future vision for Family Budget Agent.

---

## ğŸ“‹ Table of Contents

1. [Current Status](#current-status)
2. [Known Limitations](#known-limitations)
3. [Performance Bottlenecks](#performance-bottlenecks)
4. [Phase 2: Optimizations (v2.1)](#phase-2-optimizations-v21---in-progress)
5. [Phase 3: New Features (v2.2)](#phase-3-new-features-v22---planned)
6. [Phase 4: Advanced (v3.0)](#phase-4-advanced-v30---future-vision)
7. [Known Issues & Workarounds](#known-issues--workarounds)
8. [Contribution Opportunities](#contribution-opportunities)
9. [Experimental Features](#experimental-features)

---

## âœ… Current Status (v2.0)

### Production Ready Features

```
âœ… Core System
â”œâ”€â”€ CSV processing with dual-LLM pipeline
â”œâ”€â”€ Monthly budget merging
â”œâ”€â”€ Annual file management
â”œâ”€â”€ OneDrive sync integration
â””â”€â”€ Modular plugin architecture

âœ… AI Chat System
â”œâ”€â”€ 3-tier data access (Python â†’ Summary â†’ Full Data)
â”œâ”€â”€ Confidence tracking (5-component scoring)
â”œâ”€â”€ Bilingual support (ä¸­æ–‡/English auto-detect)
â”œâ”€â”€ Guardrails (whitelist-only topic enforcement)
â””â”€â”€ Response formatting with emojis

âœ… Visualization
â”œâ”€â”€ Rich terminal tables (with colors & trends)
â”œâ”€â”€ Terminal graphs (ASCII charts via plotext)
â”œâ”€â”€ GUI charts (matplotlib with Chinese fonts)
â””â”€â”€ Interactive menus

âœ… Dual-LLM Mix Model
â”œâ”€â”€ Qwen3:8b (structured tasks, 5.2GB)
â”œâ”€â”€ GPT-OSS:20b (deep reasoning, 13GB)
â”œâ”€â”€ Smart orchestration & automatic handoff
â””â”€â”€ Confidence-based collaboration
```

### System Metrics (Current)

| Component | Performance | Status |
|-----------|-------------|--------|
| CSV processing (45 tx) | ~8 seconds | âœ… Good |
| Simple chat query (Tier 1) | <1 second | âœ… Excellent |
| Medium query (Tier 2) | ~5 seconds | âœ… Good |
| Complex query (Tier 3) | ~15 seconds | âš ï¸ Can optimize |
| GUI chart generation | 3-5 seconds | âš ï¸ Can optimize |
| Language detection | ~0.1s, 95% acc | âœ… Good |
| Duplicate detection | 98% accuracy | âœ… Excellent |
| Category accuracy | 95%+ | âœ… Excellent |

---

## âš ï¸ Known Limitations

### 1. AI Chat Complexity Limits ğŸ¤–

**Issue:**
- Max 15 words per question
- Single-part questions only
- No conditional reasoning ("if X then Y")
- No multi-step analysis

**Examples That Fail:**
```
âŒ "å¦‚æœæ¸›å°‘ä¼™é£Ÿè²»ï¼Œæœƒçœå¤šå°‘ï¼Œé‚„æœ‰æ‡‰è©²æ€éº¼åšï¼Ÿ"
   (Too many parts: if/save/what to do)

âŒ "Can you tell me how much I spent on food in July 
   and also compare it with August and tell me why?"
   (Multi-part: ask + compare + explain)

âŒ "ä½ è¦ºå¾—å“ªå€‹æœˆæœ€å¥½ï¼Ÿ"
   (Opinion/subjective - no data basis)
```

**Current Workaround:**
Break into multiple simple questions:
```
âœ… Q1: "ä¸ƒæœˆä¼™é£Ÿè²»å¤šå°‘ï¼Ÿ"
âœ… Q2: "å…«æœˆä¼™é£Ÿè²»å¤šå°‘ï¼Ÿ"
âœ… Q3: "ç‚ºä»€éº¼å…«æœˆå¢åŠ ï¼Ÿ"
```

**Planned Fix:** 
- **v2.1** - Question decomposition engine
- Automatically break complex questions into simple ones
- Answer each part, combine results
- **Complexity:** High
- **ETA:** 2-3 months
- **Impact:** Answer 30% more questions

---

### 2. No LLM Response Caching ğŸ’¾

**Issue:**
Every similar/repeated question queries LLM again

**Impact:**
```
Q1: "ä¸ƒæœˆèŠ±äº†å¤šå°‘ï¼Ÿ" â†’ 5s (Tier 2)
[Wait 1 minute]
Q2: "ä¸ƒæœˆèŠ±äº†å¤šå°‘ï¼Ÿ" â†’ 5s (Same query, no cache!)

Expected with cache: <0.5s
```

**Why It Matters:**
- Users often ask similar questions
- Wastes resources (tokens, time)
- Poor UX for repeated queries

**Planned Fix:**
- **v2.1** - Redis-like in-memory cache
- 1-hour TTL (Time To Live)
- Cache key: hash(question + relevant data)
- Invalidate on data update
- **Complexity:** Medium
- **ETA:** 1-2 months
- **Impact:** 40% speed improvement for repeated queries

---

### 3. GUI Charts Slow ğŸ“Š

**Issue:**
- 3-5 seconds to generate matplotlib charts
- Blocks UI during generation
- Chinese font loading adds overhead

**Why:**
```
Chart Generation Process:
â”œâ”€â”€ Matplotlib init: 1.5s
â”œâ”€â”€ Chinese font load: 0.8s
â”œâ”€â”€ Data processing: 0.3s
â”œâ”€â”€ Rendering: 0.9s
â””â”€â”€ Total: ~3.5s
```

**Current Workaround:**
Use terminal charts (instant, ASCII-based)

**Planned Fix:**
- **v2.2** - Async chart generation
- Generate in background thread
- Show progress indicator
- Cache rendered charts
- **Complexity:** Medium
- **ETA:** 3-4 months
- **Impact:** UI stays responsive, perceived speed 2x

---

### 4. Fuzzy Duplicate Detection Limited ğŸ”

**Issue:**
- Rule-based duplicate detection: 98% accurate
- LLM-assisted fuzzy matching: ~85% accurate
- Edge cases still need manual review

**Examples That Fail:**
```
Transaction 1: "å®¶æ¨‚ç¦ - è³¼ç‰©"  NT$1,523  2025-07-15
Transaction 2: "Carrefour"      NT$1,523  2025-07-15
â†’ Should be duplicate, but descriptions differ

Transaction 1: "Starbucks"  NT$150  2025-07-10 09:30
Transaction 2: "Starbucks"  NT$150  2025-07-10 14:20
â†’ Same day, same amount, but different transactions!
```

**Current Workaround:**
Manual review of flagged uncertain duplicates

**Planned Fix:**
- **v2.1** - Learning mode
- Log user corrections
- Improve patterns over time
- Confidence-weighted learning
- **Complexity:** Medium
- **ETA:** 2-3 months
- **Impact:** 95%+ accuracy after 3 months of learning

---

### 5. Multi-Year Analysis UI Incomplete ğŸ“…

**Issue:**
- Backend exists (`multi_year_data_loader.py`)
- Data loading works
- UI integration incomplete
- Can't compare 2024 vs 2025 in chat

**What Works:**
```python
# Backend (works):
loader = MultiYearDataLoader()
data = loader.load_years([2024, 2025])
comparison = loader.compare_years(2024, 2025)
```

**What Doesn't Work:**
```
User: "æ¯”è¼ƒ2024å’Œ2025å¹´çš„ä¼™é£Ÿè²»"
AI: "æŠ±æ­‰ï¼Œæˆ‘æ²’æœ‰é€™å€‹ç­”æ¡ˆ" (no UI routing)
```

**Current Workaround:**
Use Python console to access backend directly

**Planned Fix:**
- **v2.1** - Complete UI integration
- Add to AI Chat question classifier
- Add to visual reports menu
- Multi-year charts
- **Complexity:** Low (backend done)
- **ETA:** 1 month
- **Impact:** Year-over-year analysis available

---

### 6. Language Detection Edge Cases ğŸŒ

**Issue:**
- ~95% accuracy (good but not perfect)
- Mixed language sentences problematic
- Very short questions harder to detect

**Examples:**
```
âš ï¸ "Show ä¸ƒæœˆ data"
   Detected as: English (60% conf)
   Should detect: Mixed â†’ use context

âš ï¸ "å¤šå°‘ï¼Ÿ" (too short - 2 words)
   Detected with: Low confidence
   May default to wrong language

âœ… "ä¸ƒæœˆèŠ±äº†å¤šå°‘ï¼Ÿ" (clear Chinese)
   Detected correctly: 95% conf
```

**Current Workaround:**
- Use more keywords in preferred language
- Set default language in config

**Planned Fix:**
- **v2.1** - Improved detection algorithm
- Context-aware detection (conversation history)
- Mixed language support
- User preference learning
- **Complexity:** Medium
- **ETA:** 2 months
- **Impact:** 98%+ accuracy

---

### 7. No Relative Date Support ğŸ“†

**Issue:**
Only absolute dates/months work

**Examples That Don't Work:**
```
âŒ "ä»Šå¤©èŠ±äº†å¤šå°‘ï¼Ÿ" (today)
âŒ "ä¸Šé€±çš„æ”¯å‡º" (last week)
âŒ "é€™å€‹æœˆ" (this month)
âŒ "æœ€è¿‘ä¸‰å€‹æœˆ" (recent 3 months)

âœ… "7æœˆ15æ—¥"
âœ… "ä¸ƒæœˆ"
âœ… "2024å¹´å…«æœˆ"
```

**Current Workaround:**
Calculate date manually, use explicit dates

**Planned Fix:**
- **v2.2** - Relative date parser
- Map "ä»Šå¤©" â†’ current date
- Map "ä¸Šé€±" â†’ last 7 days
- Map "é€™å€‹æœˆ" â†’ current month
- **Complexity:** Low
- **ETA:** 2-3 months
- **Impact:** More natural conversation

---

### 8. Context Window Limited ğŸ§ 

**Issue:**
- Only last 10 interactions remembered
- No long-term conversation memory
- Can't reference earlier topics

**Example:**
```
[After 15 questions]
You: "å›åˆ°æˆ‘å€‘å‰›æ‰èªªçš„é‚£å€‹å•é¡Œ"
AI: "æˆ‘ä¸è¨˜å¾—äº†" (context lost after 10 turns)
```

**Current Workaround:**
Repeat relevant context in question

**Planned Fix:**
- **v2.2** - Vector-based long-term memory
- Embed all past conversations
- Semantic search over history
- Retrieve relevant past interactions
- **Complexity:** High
- **ETA:** 4-6 months
- **Impact:** Truly conversational AI

---

### 9. No PDF/Image Export ğŸ“„

**Issue:**
- Can't save charts as images
- Can't export reports to PDF
- Can't share insights easily

**Current Workaround:**
Screenshot manually

**Planned Fix:**
- **v2.1** - Export module
- Save charts as PNG/SVG
- Export conversations to PDF
- Email report functionality
- **Complexity:** Low
- **ETA:** 1-2 months
- **Impact:** Easy sharing & archival

---

### 10. Fixed Confidence Threshold âš–ï¸

**Issue:**
- Handoff threshold hardcoded (85%)
- Not adaptive to question type
- User risk tolerance ignored

**Current:**
```python
if qwen_confidence < 0.85:
    escalate_to_gpt_oss()
```

**Better:**
```python
# Adaptive thresholds:
if question_type == 'instant':
    threshold = 0.75  # More lenient
elif question_type == 'financial_advice':
    threshold = 0.95  # Very strict
```

**Planned Fix:**
- **v2.2** - Dynamic thresholds
- Per-question-type thresholds
- User preference setting
- Learn from feedback
- **Complexity:** Medium
- **ETA:** 3-4 months
- **Impact:** Better quality/speed trade-off

---

## ğŸ“Š Performance Bottlenecks

### Current Performance Profile

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CSV Processing (45 transactions)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Load CSV:                0.1s  âœ…                        â”‚
â”‚ Qwen categorization:     3.2s  âš ï¸ CAN OPTIMIZE (batch)  â”‚
â”‚ GPT-OSS refinement:      4.5s  âš ï¸ CAN OPTIMIZE (cache)  â”‚
â”‚ Merge to Excel:          0.3s  âœ…                        â”‚
â”‚ Save Excel:              0.5s  âœ…                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL:                   8.6s                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI Chat Query (varies by tier)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Tier 1 (Python):         0.2s  âœ… OPTIMAL               â”‚
â”‚ Tier 2 (Summary):        5.3s  âš ï¸ CAN CACHE             â”‚
â”‚ Tier 3 (Full Data):     18.7s  ğŸ”´ NEEDS OPTIMIZATION    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ No caching currently - every query hits LLM             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Visual Reports                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Terminal charts:         0.5s  âœ… OPTIMAL               â”‚
â”‚ GUI charts:              3.2s  âš ï¸ CAN LAZY LOAD         â”‚
â”‚ Rich tables:             0.1s  âœ… OPTIMAL               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Memory Usage (both LLMs loaded)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Qwen3:8b:                5.2GB                           â”‚
â”‚ GPT-OSS:20b:            13.0GB                           â”‚
â”‚ Python process:          0.5GB                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TOTAL:                  18.7GB  âš ï¸ High but manageable  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Optimization Opportunities

#### 1. Batch Categorization ğŸ“¦

**Current:**
```python
# Process one transaction at a time
for tx in transactions:
    category = qwen.categorize(tx)  # 45 LLM calls!
```

**Optimized:**
```python
# Process in batches of 10
for batch in chunk(transactions, 10):
    categories = qwen.categorize_batch(batch)  # 5 LLM calls
```

**Expected Impact:**
- Speed: 6x faster (8s â†’ 1.5s for CSV processing)
- Quality: Same or better (context helps)
- **Complexity:** Low
- **ETA:** v2.1 (1 month)

---

#### 2. Response Caching ğŸ’¾

**Current:**
```python
answer = llm.query(question)  # Always hits LLM
```

**Optimized:**
```python
cache_key = hash(question + data_hash)
if cache_key in cache:
    return cache[cache_key]  # < 0.5s
else:
    answer = llm.query(question)
    cache[cache_key] = answer
    return answer
```

**Expected Impact:**
- Speed: 10x faster for repeated queries
- Cache hit rate: ~70% (typical usage)
- **Complexity:** Medium
- **ETA:** v2.1 (2 months)

---

#### 3. Lazy Chart Generation ğŸ¨

**Current:**
```python
# Generate all chart types
terminal_chart = generate_terminal_chart()  # 0.5s
gui_chart = generate_gui_chart()           # 3.5s
table = generate_table()                    # 0.1s
# Total: 4.1s
```

**Optimized:**
```python
# Generate only what user requests
table = generate_table()  # Always show (0.1s)
# User chooses: terminal or GUI
if user_choice == 'terminal':
    chart = generate_terminal_chart()  # 0.5s
elif user_choice == 'gui':
    chart = generate_gui_chart_async()  # 3.5s background
```

**Expected Impact:**
- Speed: 2x faster perceived performance
- Resource: Lower memory usage
- **Complexity:** Low
- **ETA:** v2.1 (1 month)

---

#### 4. Tier 3 Data Pruning âœ‚ï¸

**Current:**
```python
# Send ALL transactions to LLM
data = load_month('ä¸ƒæœˆ')  # 100 transactions
answer = llm.analyze(question, data)  # 5000 tokens!
```

**Optimized:**
```python
# Filter first, send only relevant data
data = load_month('ä¸ƒæœˆ')
relevant = filter_by_entities(data, question)  # 15 transactions
answer = llm.analyze(question, relevant)  # 800 tokens
```

**Expected Impact:**
- Speed: 2x faster Tier 3 queries
- Accuracy: Higher (less noise)
- Cost: 85% fewer tokens
- **Complexity:** Medium
- **ETA:** v2.1 (2 months)

---

#### 5. Model Quantization ğŸ—œï¸

**Current:**
```
qwen3:8b â†’ 5.2GB (full precision)
gpt-oss:20b â†’ 13GB (full precision)
Total: 18.2GB
```

**Optimized:**
```
qwen3:8b-Q4_K_M â†’ 2.6GB (quantized)
gpt-oss:20b-Q4_K_M â†’ 6.5GB (quantized)
Total: 9.1GB (50% smaller!)
```

**Expected Impact:**
- Memory: 50% reduction
- Speed: Same or slightly faster
- Quality: Minimal loss (<2%)
- **Complexity:** Low (just change model names)
- **ETA:** Can do now!

---

## ğŸ”„ Phase 2: Optimizations (v2.1) - IN PROGRESS

**Timeline:** Next 1-3 months  
**Focus:** Speed, efficiency, quality improvements

### 1. LLM Response Caching ğŸ’¾

**Status:** ğŸ”´ Not Started  
**Priority:** ğŸ”´ High  
**Difficulty:** Medium  
**ETA:** 2 months

**Goals:**
- Implement Redis-like in-memory cache
- 1-hour TTL (configurable)
- Cache invalidation on data update
- Hash-based cache keys

**Expected Impact:**
- 40% faster average response time
- 70% cache hit rate
- Better user experience for repeated queries

**Implementation Plan:**
```python
class ResponseCache:
    def __init__(self, ttl=3600):
        self.cache = {}  # {key: (value, timestamp)}
        self.ttl = ttl
    
    def get(self, question, data_hash):
        key = hash(question + data_hash)
        if key in self.cache:
            value, timestamp = self.cache[key]
            if time.time() - timestamp < self.ttl:
                return value
        return None
    
    def set(self, question, data_hash, answer):
        key = hash(question + data_hash)
        self.cache[key] = (answer, time.time())
```

---

### 2. Question Decomposition ğŸ§©

**Status:** ğŸŸ¡ Researching  
**Priority:** ğŸ”´ High  
**Difficulty:** High  
**ETA:** 3 months

**Goals:**
- Automatically break complex questions into simple ones
- Answer each sub-question
- Combine results intelligently

**Example:**
```
Input: "ä¸ƒæœˆå’Œå…«æœˆçš„ä¼™é£Ÿè²»åˆ†åˆ¥æ˜¯å¤šå°‘ï¼Œç‚ºä»€éº¼å…«æœˆå¢åŠ ï¼Ÿ"

Decomposition:
â”œâ”€ Q1: "ä¸ƒæœˆçš„ä¼™é£Ÿè²»æ˜¯å¤šå°‘ï¼Ÿ"
â”œâ”€ Q2: "å…«æœˆçš„ä¼™é£Ÿè²»æ˜¯å¤šå°‘ï¼Ÿ"
â””â”€ Q3: "ç‚ºä»€éº¼å…«æœˆä¼™é£Ÿè²»å¢åŠ ï¼Ÿ"

Combined Answer:
"ä¸ƒæœˆä¼™é£Ÿè²»NT$15,420ï¼Œå…«æœˆNT$18,650 (å¢åŠ 21%)ã€‚
å…«æœˆå¢åŠ ä¸»è¦å› ç‚ºå¤–é£Ÿæ¬¡æ•¸å¢åŠ ..."
```

**Expected Impact:**
- Answer 30% more questions
- No more "question too complex" rejections
- Better user experience

---

### 3. Batch Categorization ğŸ“¦

**Status:** ğŸŸ¢ Design Complete  
**Priority:** ğŸŸ¡ Medium  
**Difficulty:** Low  
**ETA:** 1 month

**Goals:**
- Process 10 transactions per LLM call
- Maintain or improve accuracy

**Implementation:**
```python
# Current (45 calls for 45 transactions)
for tx in transactions:
    category = qwen.categorize(tx)

# New (5 calls for 45 transactions)
for batch in chunk(transactions, 10):
    categories = qwen.categorize_batch(batch)
```

**Expected Impact:**
- 6x faster CSV processing
- 8.6s â†’ 1.5s processing time

---

### 4. Learning Mode ğŸ“

**Status:** ğŸŸ¡ 70% Complete (Backend Ready)  
**Priority:** ğŸŸ¡ Medium  
**Difficulty:** Medium  
**ETA:** 2 months

**Goals:**
- Log user corrections to categorization
- Improve patterns over time
- Confidence-weighted learning

**What's Done:**
```python
# Backend exists:
class LearningModule:
    def log_correction(self, tx, wrong_cat, correct_cat):
        # Logs to corrections.jsonl
        pass
    
    def get_learned_patterns(self):
        # Returns improved patterns
        pass
```

**What's Needed:**
- UI to show & confirm corrections
- Pattern extraction algorithm
- Integration with categorizer

**Expected Impact:**
- 95%+ categorization accuracy after 3 months
- Fewer manual corrections needed

---

### 5. Multi-Year UI Integration ğŸ“…

**Status:** ğŸŸ¡ 70% Complete (Backend Ready)  
**Priority:** ğŸŸ¡ Medium  
**Difficulty:** Low  
**ETA:** 1 month

**Goals:**
- Integrate `multi_year_data_loader.py` with AI Chat
- Enable year-over-year comparisons
- Multi-year charts

**What's Done:**
```python
# Backend works:
loader = MultiYearDataLoader()
data_2024 = loader.load_year(2024)
data_2025 = loader.load_year(2025)
comparison = loader.compare_years(2024, 2025)
```

**What's Needed:**
- Add to question classifier
- Add to visual reports menu
- Year selection UI

**Expected Impact:**
- Full year-over-year analysis
- Historical trend visibility

---

### 6. PDF Export ğŸ“„

**Status:** ğŸ”´ Not Started  
**Priority:** ğŸŸ¢ Low  
**Difficulty:** Low  
**ETA:** 1 month

**Goals:**
- Export conversations to PDF
- Save charts as PNG/SVG
- Email reports

**Libraries to Use:**
- `reportlab` - PDF generation
- `matplotlib.savefig()` - Chart export
- `smtplib` - Email (optional)

**Expected Impact:**
- Easy sharing & archival
- Professional reports

---

### 7. Improved Language Detection ğŸŒ

**Status:** ğŸ”´ Not Started  
**Priority:** ğŸŸ¢ Low  
**Difficulty:** Medium  
**ETA:** 2 months

**Goals:**
- 98%+ accuracy (from 95%)
- Better mixed language support
- Context-aware detection

**Approach:**
- Use conversation history
- Weight by keyword count
- Fuzzy language matching

**Expected Impact:**
- Fewer language misdetections
- Better mixed language handling

---

## ğŸ¯ Phase 3: New Features (v2.2) - PLANNED

**Timeline:** 3-6 months  
**Focus:** New capabilities, major enhancements

### 1. Budget Goals & Tracking ğŸ¯

**Status:** ğŸ”´ Not Started  
**Priority:** ğŸ”´ High  
**Difficulty:** Medium  
**ETA:** 3 months

**Features:**
- Set monthly/yearly goals per category
- Real-time progress tracking
- Alert when approaching limits
- Goal achievement analytics

**Example UI:**
```
è¨­å®šé ç®—ç›®æ¨™

ä¼™é£Ÿè²»: NT$15,000/æœˆ
ç›®å‰æ”¯å‡º: NT$12,300 (82%)
ğŸŸ¢ åœ¨é ç®—å…§

äº¤é€šè²»: NT$5,000/æœˆ
ç›®å‰æ”¯å‡º: NT$5,400 (108%)
ğŸ”´ å·²è¶…æ”¯ NT$400

[è¨­å®šæé†’: é”åˆ°90%æ™‚é€šçŸ¥]
```

---

### 2. Spending Alerts ğŸ””

**Status:** ğŸ”´ Not Started  
**Priority:** ğŸŸ¡ Medium  
**Difficulty:** Medium  
**ETA:** 4 months

**Features:**
- Real-time anomaly detection
- Proactive notifications
- Configurable thresholds
- Weekly/monthly summaries

**Examples:**
```
âš ï¸ ç•°å¸¸æ”¯å‡ºè­¦å‘Š
8æœˆ15æ—¥ - ä¼‘é–’/å¨›æ¨‚: NT$5,000
é€™æ˜¯æ‚¨å¹³å‡æ”¯å‡ºçš„3å€
ç¢ºèªé€™ç­†äº¤æ˜“ï¼Ÿ

ğŸ’¡ æ¯é€±æé†’
æœ¬é€±å·²èŠ±è²» NT$3,200
è·é›¢é€±é ç®—é‚„å‰© NT$800
å»ºè­°ç¯€åˆ¶å¤–é£Ÿ
```

---

### 3. Relative Date Support ğŸ“†

**Status:** ğŸ”´ Not Started  
**Priority:** ğŸŸ¡ Medium  
**Difficulty:** Low  
**ETA:** 3 months

**Features:**
- Support "ä»Šå¤©", "æ˜¨å¤©", "ä¸Šé€±"
- Support "é€™å€‹æœˆ", "ä¸Šå€‹æœˆ"
- Support "æœ€è¿‘3å€‹æœˆ"

**Mapping:**
```python
"ä»Šå¤©" â†’ datetime.now().date()
"æ˜¨å¤©" â†’ datetime.now().date() - timedelta(days=1)
"ä¸Šé€±" â†’ last_7_days()
"é€™å€‹æœˆ" â†’ current_month()
"æœ€è¿‘3å€‹æœˆ" â†’ last_3_months()
```

---

### 4. Long-term Memory (Vector Store) ğŸ§ 

**Status:** ğŸ”´ Not Started  
**Priority:** ğŸŸ¡ Medium  
**Difficulty:** High  
**ETA:** 5 months

**Features:**
- Embed all past conversations
- Semantic search over history
- Retrieve relevant past context
- Learning from interaction patterns

**Technology:**
- `sentence-transformers` - Embeddings
- `faiss` or `chromadb` - Vector storage
- Semantic similarity search

**Expected Impact:**
- Truly conversational AI
- Reference past topics
- Personalized responses

---

### 5. Async Chart Generation ğŸ¨

**Status:** ğŸ”´ Not Started  
**Priority:** ğŸŸ¢ Low  
**Difficulty:** Medium  
**ETA:** 4 months

**Features:**
- Generate charts in background
- Show progress indicator
- Non-blocking UI
- Cache rendered charts

**Implementation:**
```python
import asyncio

async def generate_chart_async(data):
    # Generate in background
    chart = await asyncio.to_thread(matplotlib_render, data)
    return chart

# UI stays responsive
print("Generating chart...")
chart = await generate_chart_async(data)
print("Done!")
```

---

### 6. Dynamic Thresholds âš–ï¸

**Status:** ğŸ”´ Not Started  
**Priority:** ğŸŸ¢ Low  
**Difficulty:** Medium  
**ETA:** 4 months

**Features:**
- Per-question-type thresholds
- User risk tolerance setting
- Adaptive learning from feedback

**Example:**
```python
THRESHOLDS = {
    'instant': 0.75,           # More lenient
    'trend': 0.80,             # Moderate
    'forecast': 0.85,          # Strict
    'financial_advice': 0.95   # Very strict
}

if confidence < THRESHOLDS[question_type]:
    escalate_to_stronger_llm()
```

---

### 7. Custom Chart Themes ğŸ¨

**Status:** ğŸ”´ Not Started  
**Priority:** ğŸŸ¢ Low  
**Difficulty:** Low  
**ETA:** 3 months

**Features:**
- User-selectable color schemes
- Custom fonts & sizes
- Save preferences
- Export themes

**Examples:**
- Dark mode
- Colorblind-friendly
- High contrast
- Professional (for presentations)

---

## ğŸ”® Phase 4: Advanced (v3.0) - FUTURE VISION

**Timeline:** 6-12 months  
**Focus:** Major architectural changes, new platforms

### 1. Web Interface ğŸŒ

**Vision:**
- Browser-based UI
- Mobile responsive
- Real-time sync across devices
- No installation required

**Technology Stack:**
- Backend: FastAPI or Flask
- Frontend: React or Vue.js
- Database: PostgreSQL
- Deployment: Docker

**Expected Impact:**
- Accessible from anywhere
- Better UX than terminal
- Family collaboration easier

---

### 2. Collaborative Budgeting ğŸ‘¥

**Vision:**
- Multiple users (you + wife)
- Shared budgets & goals
- Role-based permissions
- Comments on transactions
- Approval workflows

**Features:**
```
User Roles:
â”œâ”€â”€ Admin (you): Full access
â”œâ”€â”€ Partner (wife): Full access
â””â”€â”€ Viewer (kids?): Read-only

Workflows:
â”œâ”€â”€ Flag suspicious transactions
â”œâ”€â”€ Request budget adjustments
â””â”€â”€ Approve large expenses
```

---

### 3. Bank API Integration ğŸ¦

**Vision:**
- Direct bank account connection
- Auto-import transactions
- Real-time balance updates
- No more CSV exports

**Technology:**
- Plaid API (US/Europe)
- Open Banking APIs (Taiwan?)
- OAuth2 authentication

**Benefits:**
- Zero manual work
- Always up-to-date
- Instant insights

**Challenges:**
- Privacy concerns
- Bank API availability
- Security requirements

---

### 4. Investment Tracking ğŸ“ˆ

**Vision:**
- Separate investment module
- Track portfolio performance
- Link to budget (dividend income)
- Net worth dashboard

**Features:**
- Stock/fund holdings
- P&L tracking
- Asset allocation
- Rebalancing suggestions

---

### 5. Voice Interface ğŸ¤

**Vision:**
- Ask questions via voice
- Audio responses
- Smart speaker integration (Google Home, Alexa)
- Hands-free budgeting

**Technology:**
- Speech-to-text: Whisper
- Text-to-speech: ElevenLabs or local TTS
- Wake word: "Hey Budget"

**Example:**
```
You: "Hey Budget, ä¸ƒæœˆèŠ±äº†å¤šå°‘ï¼Ÿ"
AI: "ä¸ƒæœˆç¸½æ”¯å‡º NT$27,300"
```

---

### 6. Mobile App ğŸ“±

**Vision:**
- Native iOS/Android apps
- Photo receipt scanning (OCR)
- GPS-based expense logging
- Push notifications

**Technology:**
- React Native or Flutter
- OCR: Google Vision API
- Sync: Cloud backend

---

### 7. Three-Model Architecture ğŸ¤–ğŸ¤–ğŸ¤–

**Vision:**
- Small (qwen3:8b) â†’ Medium (qwen2.5:14b) â†’ Large (gpt-oss:20b)
- More granular escalation
- Better cost/quality optimization

**Flow:**
```
Question
  â†“
Small model tries (fast, cheap)
  â†“ if uncertain
Medium model tries (balanced)
  â†“ if uncertain
Large model (slow, accurate)
```

---

## ğŸ› Known Issues & Workarounds

### Issue 1: GUI Charts Don't Show Over SSH

**Cause:** No display server available

**Workaround:** Use terminal charts (ASCII-based)

**Command:**
```
Choose terminal charts when prompted
or
Add to config: DEFAULT_CHART_TYPE = 'terminal'
```

**Status:** Won't fix (expected behavior)

---

### Issue 2: Confidence Sometimes 0% for Valid Budget Questions

**Cause:** Language detection failure or missing keywords

**Example:**
```
Q: "è²»ç”¨" (too vague)
â†’ Confidence: 0% (rejected as unclear)
```

**Workaround:** Add more context/keywords
```
âœ… "ä¸ƒæœˆçš„è²»ç”¨"
âœ… "ä¼™é£Ÿè²»ç”¨"
```

**Status:** ğŸ”§ Improved detection in v2.1

---

### Issue 3: Category Names Must Be Exact

**Cause:** No fuzzy matching implemented

**Example:**
```
âŒ "ä¼™é£Ÿ" (incomplete)
âŒ "é£Ÿç‰©è²»" (synonym)
âœ… "ä¼™é£Ÿè´¹" (exact)
```

**Workaround:** Use exact category names from Excel

**Status:** ğŸ”§ Fuzzy matching planned for v2.1

---

### Issue 4: Numeric Month Not Always Recognized

**Cause:** Question classifier prioritizes Chinese months

**Example:**
```
âš ï¸ "7æœˆ" sometimes not detected
âœ… "ä¸ƒæœˆ" always works
âœ… "July" always works
```

**Workaround:** Use Chinese characters or English

**Status:** ğŸ”§ Fixed in v2.0 (should work now)

---

### Issue 5: Long Questions Timeout

**Cause:** LLM timeout (default 180s)

**When It Happens:**
- Very long questions (>50 words)
- Tier 3 queries with large datasets (>200 transactions)

**Workaround:** Increase timeout in config
```python
# config.py
LLM_CONFIG = {
    "reasoning": {
        "timeout": 300,  # 5 minutes
    }
}
```

**Status:** âš ï¸ Rare occurrence, no fix planned

---

## ğŸ¤ Contribution Opportunities

### ğŸ”´ High Priority (Help Wanted!)

#### 1. LLM Response Caching
- **Skills:** Python, caching patterns
- **Difficulty:** Medium
- **Impact:** High (40% speed improvement)
- **Files:** `modules/insights/ai_chat.py`

#### 2. Question Decomposition
- **Skills:** NLP, LLM prompting
- **Difficulty:** High
- **Impact:** High (30% more questions answered)
- **Files:** `modules/insights/question_classifier.py`

#### 3. PDF Export
- **Skills:** Python, reportlab
- **Difficulty:** Low
- **Impact:** Medium (better sharing)
- **Files:** New module `modules/insights/export.py`

---

### ğŸŸ¡ Medium Priority

#### 4. Multi-Year Charts
- **Skills:** Matplotlib, data visualization
- **Difficulty:** Medium
- **Impact:** Medium (historical insights)
- **Files:** `modules/insights/gui_graphs.py`

#### 5. Batch Categorization
- **Skills:** Python, LLM prompting
- **Difficulty:** Low
- **Impact:** High (6x faster processing)
- **Files:** `modules/llm/qwen_engine.py`

#### 6. Learning Mode UI
- **Skills:** Python, terminal UI
- **Difficulty:** Medium
- **Impact:** Medium (better accuracy)
- **Files:** `_main.py`, `modules/data/simple_categorizer.py`

---

### ğŸŸ¢ Low Priority (Good First Issues)

#### 7. Custom Chart Themes
- **Skills:** CSS-like styling, matplotlib
- **Difficulty:** Low
- **Impact:** Low (aesthetic)
- **Files:** `modules/insights/gui_graphs.py`

#### 8. Relative Date Parser
- **Skills:** Python, regex, datetime
- **Difficulty:** Low
- **Impact:** Medium (better UX)
- **Files:** `modules/insights/question_classifier.py`

#### 9. Improved Error Messages
- **Skills:** Writing, Python
- **Difficulty:** Very Low
- **Impact:** Low (better UX)
- **Files:** Various

---

## ğŸ”¬ Experimental Features (Testing Phase)

### 1. Streaming Responses ğŸŒŠ

**Status:** Prototype exists, not integrated

**Concept:** Show answer as it generates (like ChatGPT)

**Benefit:** Perceived faster response

**Risk:** Confidence tracking harder (need full response)

**Next Steps:**
- Test with simple questions
- Measure user satisfaction
- Implement confidence on stream complete

---

### 2. Multi-Model Voting ğŸ—³ï¸

**Status:** Research phase

**Concept:** Ask 3 models, take consensus

**Example:**
```
Question: "ä¸ƒæœˆèŠ±äº†å¤šå°‘ï¼Ÿ"
â”œâ”€ Model 1 (Qwen): NT$27,300
â”œâ”€ Model 2 (GPT-OSS): NT$27,300
â””â”€ Model 3 (Llama): NT$27,350

Consensus: NT$27,300 (2/3 agree)
Confidence: 95% (high agreement)
```

**Benefit:** Higher accuracy for critical decisions

**Risk:** 3x slower, 3x more expensive

**Use Case:** Financial advice, large transactions

**Timeline:** Experiment in v2.2

---

### 3. Local Embedding Search ğŸ”

**Status:** Not started

**Concept:** Semantic search over all transactions

**Technology:**
- `sentence-transformers` - Generate embeddings
- `faiss` - Fast similarity search

**Example:**
```
Question: "å’–å•¡ç›¸é—œçš„æ”¯å‡º"

Traditional: Exact match "å’–å•¡" â†’ 5 transactions

Semantic Search:
â”œâ”€ "Starbucks" (0.92 similarity)
â”œâ”€ "85åº¦C" (0.89 similarity)
â”œâ”€ "æ—©é¤åº—é£²æ–™" (0.75 similarity)
â””â”€ Total: 15 transactions
```

**Benefit:** Better context for LLM, more complete answers

**Risk:** Requires vector database, more complexity

**Timeline:** Research in v2.2

---

## ğŸ“Š Progress Tracking

### v2.0 âœ… (Current - Complete)

```
âœ… Core System (100%)
âœ… Dual-LLM Mix Model (100%)
âœ… AI Chat with 3-tier (100%)
âœ… Confidence Tracking (100%)
âœ… Visual Reports (100%)
âœ… Bilingual Support (100%)
```

---

### v2.1 ğŸ”„ (In Progress - 0%)

```
ğŸ”´ LLM Response Caching (0%)
ğŸŸ¡ Question Decomposition (5% - research)
ğŸŸ¢ Batch Categorization (80% - design done)
ğŸŸ¡ Learning Mode (70% - backend done)
ğŸŸ¡ Multi-Year UI (70% - backend done)
ğŸ”´ PDF Export (0%)
ğŸ”´ Improved Language Detection (0%)
```

**Overall Progress:** 25% (design phase)  
**ETA:** 3 months

---

### v2.2 ğŸ“‹ (Planned - 0%)

```
ğŸ”´ Budget Goals & Tracking (0%)
ğŸ”´ Spending Alerts (0%)
ğŸ”´ Relative Date Support (0%)
ğŸ”´ Long-term Memory (0%)
ğŸ”´ Async Charts (0%)
ğŸ”´ Dynamic Thresholds (0%)
ğŸ”´ Custom Themes (0%)
```

**Overall Progress:** 0% (planning phase)  
**ETA:** 6 months

---

## ğŸ“ Feedback & Suggestions

Have ideas for improvements? Found a bug?

1. **Issues:** Use for bugs, specific problems
2. **Discussions:** Use for feature requests, ideas
3. **Pull Requests:** Contribute directly!

**Priority areas for feedback:**
- AI Chat question types you want supported
- Performance bottlenecks you've experienced
- Features you'd use most
- Integration requests (banks, tools, etc.)

---

**Roadmap Version:** 1.0  
**Last Updated:** 2025-01-22  
**Status:** Living Document (Updated Regularly)

---

Built with continuous improvement in mind ğŸš€

